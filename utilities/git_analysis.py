import subprocess
import datetime
import glob
import json
import os
import hashlib
import gzip

####################################
# Analysis process
####################################
# run "git_secrets_grabber('git_parent_directory')"" - returns a hash that has entries for each discovered repository under parent dir, and subentries for each search term -> repo:word with subkeys raw, parsed, search
# look at "search" output for each search string, identify the valid results (any unique part of the matching line), add them to a "results" key for each repo:word hash entry
# once you're done, process with "gitsearch_results_parser" function - it finds entries that have the strings from "results" in them
# can save outputs with json_file_write_gz, json_file_write functions
# can further parse output with "git_results_file_data" function, easily show results etc

# output can be (for git results gr):
#  * files for each repo containing secrets - print('\n'.join(sorted(gr[repo].keys())))
#  * matching lines and line numbers showing content matching the search terms, check you are outputting correct results - git_results_file_data(gr)
#  * appendix data = git_results_file_data(data, contents=['matches', 'commits'])
####################################


####################################
# Automation of these commands
# git grep -in 'search_string' $(git rev-list --all)
# git show <revision>/<file>

#filename search
#git rev-list --all | xargs -I '{}' git ls-tree --full-tree -r '{}' | grep target_filename.txt | sort -u

####################################

git = '/usr/bin/git'
# search terms to look for in each repo
words = [
    'access',
    'key',
    'password',
    'secret',
    'token'
]


parser = lambda x : [a.split(':', 3) for a in x.split('\n') if a]

def timestamp():
    return datetime.datetime.now().strftime('%Y%m%d%H%M%s')


def get_gitdir(base):
    '''Get git repos recursively under a provided parent directory'''
    return [a[::-1].replace('/.git'[::-1], '', 1)[::-1] for a in glob.iglob('{}/**/.git'.format(base.rstrip('/')), recursive=True)]


def git_rev_list(git_command, repo):
    '''Get list of commits from a git repo'''
    proc = subprocess.Popen([git_command, 'rev-list', '--all'], stdout=subprocess.PIPE, bufsize=1024000, cwd=repo)
    out = [a for a in proc.stdout.read().decode('UTF-8').split('\n') if a]
    proc.terminate()
    return out


def git_grep(git_command, search_pattern, repo):
    '''Run git grep command against all commits in a repo, case insensitive, providing line number of match'''
    revlist = git_rev_list(git_command, repo)
    proc = subprocess.Popen([git_command, 'grep', '-in', search_pattern] + revlist, stdout=subprocess.PIPE, bufsize=1024000, cwd=repo)
    out =  proc.stdout.read().decode('UTF-8')
    proc.terminate()
    return out



#git show REVISION:path/to/file
def git_get_file(repo, revision, file_path, git_command=git):
    proc = subprocess.Popen([git_command, 'show', '{}:{}'.format(revision, file_path) ], stdout=subprocess.PIPE, bufsize=1024000, cwd=repo)
    out =  proc.stdout.read().decode('UTF-8')
    proc.terminate()
    return out



def git_secrets_grabber(basedir, words=words, git_command=git):
    '''Grab git secrets of all reppos underneath provided parent directory'''
    repos = get_gitdir(basedir)

    data = {}

    for repo in repos:
        data[repo] = {}
        for word in words:
            data[repo][word] = {}
            data[repo][word]['raw'] = git_grep(git_command, word, repo)
            data[repo][word]['parsed'] = parser(data[repo][word]['raw'])
            data[repo][word]['search'] = sorted(set([a[-1] for a in data[repo][word]['parsed']]))
    return data


def sha1hash(data):
    return hashlib.sha1(data.encode()).hexdigest()


def json_file_write_gz(filebase, data):
    gzip.open('{}_{}.json.gz'.format(filebase, timestamp()) ,'w' ).write(json.dumps(data, indent=4, sort_keys=True).encode())


def json_file_write(filebase, data):
    open('{}_{}.json'.format(filebase, timestamp()) ,'w' ).write(json.dumps(data, indent=4, sort_keys=True))


def json_file_read_gz(filename):
    return json.loads(gzip.open(filename).read())


def json_file_read(filename):
    return  json.loads(open(filename).read())


# produces hash
# repo:filename:fileinstance:[commits:matches]
# fileinstance is a sha1 hash of the file content

# add to results subkey under search entry and run me
def gitsearch_results_parser(data):
    out = {}
    for repo in data.keys():
        out[repo] = {}
        for search_pattern in data[repo].keys():
            if 'results' in data[repo][search_pattern]:
                for result in data[repo][search_pattern]['results']:
                    dictme = lambda y : {k: v for k,v in zip(['commit', 'filename', 'line', 'match'], y) }
                    
                    for match in [dictme(a) for a in data[repo][search_pattern]['parsed'] if result in a[-1] ]:
                        
                        if match['filename'] not in out[repo]:
                            out[repo][match['filename']] = {}

                        fc = git_get_file(repo, match['commit'], match['filename'])
                        fh = sha1hash(fc)
                        
                        if fh not in out[repo][match['filename']]:
                            out[repo][match['filename']][fh] = {}
                            out[repo][match['filename']][fh]['content'] = fc
                            out[repo][match['filename']][fh]['commits'] = []
                            out[repo][match['filename']][fh]['matches'] = []

                        
                        if match['commit'] not in out[repo][match['filename']][fh]['commits']:
                            out[repo][match['filename']][fh]['commits'].append(match['commit'])

                        if [match['line'], match['match']] not in out[repo][match['filename']][fh]['matches']:
                            out[repo][match['filename']][fh]['matches'].append([match['line'], match['match']])

    return out


# content, matches, commits are valid values for contents
def git_results_file_data(data, repos=None, filenames=None, contents=['matches']):
    hashable_parser = lambda x : tuple(x) if isinstance(x, list) else x
    out = {}
    if repos == None:
        repos = list(data.keys())

    for repo in (a for a in data.keys() if a in repos):
        out[repo] = {}
        if filenames == None:
            cfilenames = list(data[repo].keys())
        else:
            cfilenames = filenames
        for filename in [a for a in data[repo].keys() if a in cfilenames]:
            if not filename in out[repo]:
                out[repo][filename] = {}
                for content in contents:
                    out[repo][filename][content] = []
                
            for fileinstance in data[repo][filename].keys():
                for content in contents:
                    if data[repo][filename][fileinstance][content] not in out[repo][filename][content]:
                        out[repo][filename][content].append(data[repo][filename][fileinstance][content])
            for content in contents:
                out[repo][filename][content] = out[repo][filename][content] if content == 'content' else list(set([hashable_parser(b) for a in out[repo][filename][content] for b in a]))

    return out



# repo:filename:fileinstance:[commits:matches]
# filename:
# for an instance
#   -> commits
#   -> line numbers with secrets


def appendix_data(data, repos=None):
    out = {}
    if repos == None:
        repos = list(data.keys())

    for repo in (a for a in data.keys() if a in repos):
        out[repo] = {}
        for filename in data[repo].keys():
            out[repo][filename] = []
            for fileinstance in data[repo][filename].keys():
                out[repo][filename].append({'matches' : [a[0] for a in data[repo][filename][fileinstance]['matches']], 'commits' : data[repo][filename][fileinstance]['commits']})
    return out


def appendix_printer(data, repos=None):
    out = ''
    dd = appendix_data(data, repos=None)
    for repo in dd.keys():
        out+=repo.split('/')[-1]+'\n'
        for filename in dd[repo].keys():
            out+='\t{}'.format(filename)+'\n'
            for entry in dd[repo][filename]:
                out+='\t\tIn a unique instance of the file found in the commits below, the following lines contained identified secrets: ({})'.format(', '.join(entry['matches']))+'\n'
                for commit in entry['commits']:
                    out+='\t\t{}'.format(commit)+'\n'
                out+='\n'
    return out


def csv_output(data, repos=None):
    out = 'Repository,Filename,Commit,Line_Numbers\n'
    dd = appendix_data(data, repos=None)
    for repo in dd.keys():
        bline=repo.split('/')[-1]+','
        for filename in sorted(dd[repo].keys()):
            line=bline+filename
            for entry in dd[repo][filename]:
                for commit in entry['commits']:
                    out+='{},{},{}\n'.format(line, commit, ';'.join(entry['matches']))
    return out

